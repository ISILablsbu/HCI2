title: "Ongoing Research Projects"

projects:
  - name: "Human-in-the-Loop Digital Twin Framework for Resilient AMR Fleet Management"
    image: "/media/projects/digital_twin.png"
    description: >
      This project develops an operator-centred Digital Twin framework for resilient Autonomous Mobile Robot (AMR) fleet management in dynamic smart manufacturing environments. Building on a multi-fidelity digital architecture that combines Digital Models, Digital Shadows, surrogate-based multi objective optimisation and high-fidelity simulation, the system detects incidents such as AMR failures, machine breakdowns and demand shocks, then generates incident aware schedules in real time. A lightweight surrogate model provides rapid rescheduling within a few seconds while remaining close to high fidelity reference behaviour, enabling throughput and energy efficiency to be preserved under disruption. In parallel, a human in the loop decision layer exposes Pareto fronts, Gantt chart previews and post simulation metrics to operators, who can select preferred trade-offs, request validation via re simulation or issue policy bound overrides, all under role-based access control. Every decision is captured as a machine-readable artefact with timestamps, reason codes and override rationale, creating a single audited trail that supports governance, cross shift handover and future learning from operator choices. The framework will be instantiated and evaluated on a battery module assembly line, providing benchmark evidence on latency, robustness and operator workload for different policy modes prioritising speed, assurance or governance, and delivering a transferable blueprint for Industry 5.0 ready, human centric AMR coordination.
    link: "digitaltwin"
  # - name: "Human-Centric Spatial AR Assistance for Complex Manual (Dis)assembly"
  #   image: "/media/projects/AR.png"
  #   description: >
  #     This project develops and evaluates a human centric Spatial Augmented Reality framework that projects adaptive, light guided assembly instructions directly onto the workspace and is controlled via AI based hand gesture recognition. Building on custom MediaPipe based gesture classification, the system delivers real time pick to place guidance, error highlighting and closed loop feedback without the need for handheld or wearable devices. Controlled within subject studies are used to quantify benefits across task types and difficulty using objective metrics such as task time, picking and placement error rates, and physiological measures of cognitive load via EEG frontal alpha power, alongside NASA TLX and usability questionnaires. Results to date show substantial reductions in task time, error rates and perceived workload compared to paper and tablet instructions, with strong user preference for SAR based guidance. The project will extend these findings to more realistic industrial cases and adaptive policies, establishing SAR system as a scalable Industry 5.0 assistance technology that improves operator efficiency, accuracy and well-being in complex manual assembly.
  #   link: "sar"
