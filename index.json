[{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1770033968,"objectID":"45903c2e1d70db39c4c0de791eb0e33f","permalink":"https://hci2.uk/author/this-could-be-you/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/this-could-be-you/","section":"authors","summary":"","tags":null,"title":"This could be you","type":"newapplicant"},{"authors":["Bugra"],"categories":null,"content":"Dr Bugra Alkan is a Senior Lecturer in AI and Robotics at London South Bank University, where he leads the Human-Centred Industrial Intelligence (HCI²) Lab. He holds a PhD degree in Engineering from WMG, University of Warwick, and has held research appointments at the University of Bristol and WMG. His work sits at the intersection of industrial AI, digital twins, and human–robot collaboration, focusing on deployable methods for high-variability, safety-critical manufacturing. He is PI/Co-I on various funded projects including HAWKSBI (Innovate UK, 10004690) and TWIN-IT-ROMANS (EU Horizon, 101160215), and has contributed as a researcher to TB-PHASE (EPSRC, EP/R004757/1) and AMPLiFII 2 (Innovate UK, 104175). He has authored 50+ peer-reviewed publications with 1,000+ citations (h-index 16, i10-index 24), with work recognised through multiple Best Paper Awards including at CIRP CATS (Gothenburg). He teaches across undergraduate and postgraduate programmes, leads modules in AI and industrial cyber-physical systems, supervises doctoral and MSc research, is a Fellow of the Higher Education Academy, and serves as an Associate Editor for Industrial Robot.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1770373055,"objectID":"86cb971a8497a1d058c81bb7e73e01f2","permalink":"https://hci2.uk/author/bugra-alkan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/bugra-alkan/","section":"authors","summary":"Dr Bugra Alkan is a Senior Lecturer in AI and Robotics at London South Bank University, where he leads the Human-Centred Industrial Intelligence (HCI²) Lab. He holds a PhD degree in Engineering from WMG, University of Warwick, and has held research appointments at the University of Bristol and WMG. His work sits at the intersection of industrial AI, digital twins, and human–robot collaboration, focusing on deployable methods for high-variability, safety-critical manufacturing. He is PI/Co-I on various funded projects including HAWKSBI (Innovate UK, 10004690) and TWIN-IT-ROMANS (EU Horizon, 101160215), and has contributed as a researcher to TB-PHASE (EPSRC, EP/R004757/1) and AMPLiFII 2 (Innovate UK, 104175). He has authored 50+ peer-reviewed publications with 1,000+ citations (h-index 16, i10-index 24), with work recognised through multiple Best Paper Awards including at CIRP CATS (Gothenburg). He teaches across undergraduate and postgraduate programmes, leads modules in AI and industrial cyber-physical systems, supervises doctoral and MSc research, is a Fellow of the Higher Education Academy, and serves as an Associate Editor for Industrial Robot.\n","tags":null,"title":"Bugra Alkan","type":"authors"},{"authors":["Cajetan"],"categories":null,"content":"Cajetan Oriekezie is a PhD Researcher at London South Bank University within the College of Technology and Environment. His research sits at the intersection of Applied Artificial Intelligence and environmental sustainability, specifically focusing on the application of Large Language Models (LLMs) in Life Cycle Assessment (LCA). By integrating machine learning and Explainable AI (XAI) into environmental assessment frameworks, Cajetan aims to accelerate LCA workflows while ensuring they remain transparent, robust, and accessible for practitioners. Prior to his doctoral studies, he obtained an MSc in Computer Science (specializing in Artificial Intelligence) from Nile University of Nigeria.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1770116070,"objectID":"4f8362163c29cc21f1faa8e245633069","permalink":"https://hci2.uk/author/cajetan-oriekezie/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/cajetan-oriekezie/","section":"authors","summary":"Cajetan Oriekezie is a PhD Researcher at London South Bank University within the College of Technology and Environment. His research sits at the intersection of Applied Artificial Intelligence and environmental sustainability, specifically focusing on the application of Large Language Models (LLMs) in Life Cycle Assessment (LCA). By integrating machine learning and Explainable AI (XAI) into environmental assessment frameworks, Cajetan aims to accelerate LCA workflows while ensuring they remain transparent, robust, and accessible for practitioners. Prior to his doctoral studies, he obtained an MSc in Computer Science (specializing in Artificial Intelligence) from Nile University of Nigeria.\n","tags":null,"title":"Cajetan Oriekezie","type":"authors"},{"authors":["Fasiha"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1770033968,"objectID":"bab9c803d14cbf9c02c33f23aebee258","permalink":"https://hci2.uk/author/fasiha-usama/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/fasiha-usama/","section":"authors","summary":"","tags":null,"title":"Fasiha Usama","type":"authors"},{"authors":["Hamidu"],"categories":null,"content":"Hamidu Midlah Barrie is a PhD candidate at London South Bank University, working within the Human-Centred Industrial Intelligence Lab in the College of Technology and Environment. His research specializes in data-driven AI anomaly detection for collaborative robotic manufacturing systems, with a focus on process mining, deep learning, and real-time fault diagnosis in Cyber-Physical Industrial Automation. His work explores the integration of process discovery techniques with advanced machine learning models to enable component-level root cause attribution, predictive maintenance, and operator-actionable intelligence in Industry 4.0/5.0 smart manufacturing and automation environments.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1770116185,"objectID":"3758bbef847c908e0bc52c8b9b461795","permalink":"https://hci2.uk/author/hamidu-midlah-barrie/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/hamidu-midlah-barrie/","section":"authors","summary":"Hamidu Midlah Barrie is a PhD candidate at London South Bank University, working within the Human-Centred Industrial Intelligence Lab in the College of Technology and Environment. His research specializes in data-driven AI anomaly detection for collaborative robotic manufacturing systems, with a focus on process mining, deep learning, and real-time fault diagnosis in Cyber-Physical Industrial Automation. His work explores the integration of process discovery techniques with advanced machine learning models to enable component-level root cause attribution, predictive maintenance, and operator-actionable intelligence in Industry 4.0/5.0 smart manufacturing and automation environments.\n","tags":null,"title":"Hamidu Midlah Barrie","type":"authors"},{"authors":["Louie"],"categories":null,"content":"Louie Webb is a PhD candidate at London South Bank University, working within the Human-Centred Industrial Intelligence Lab in the School of Computer Science and Digital Technologies. His research specialises in Digital Twin-enabled adaptive manufacturing systems, with a focus on simulation, modelling, and incident-responsive Autonomous Mobile Robot (AMR) fleet management. His work explores the convergence of advanced simulation, optimisation, and human-in-the-loop decision support to enhance resilience, agility, and intelligence in manufacturing shopfloors.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1769428425,"objectID":"3bd73c118dd01a0573c9d83c110a582a","permalink":"https://hci2.uk/author/louie-webb/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/louie-webb/","section":"authors","summary":"Louie Webb is a PhD candidate at London South Bank University, working within the Human-Centred Industrial Intelligence Lab in the School of Computer Science and Digital Technologies. His research specialises in Digital Twin-enabled adaptive manufacturing systems, with a focus on simulation, modelling, and incident-responsive Autonomous Mobile Robot (AMR) fleet management. His work explores the convergence of advanced simulation, optimisation, and human-in-the-loop decision support to enhance resilience, agility, and intelligence in manufacturing shopfloors.\n","tags":null,"title":"Louie Webb","type":"authors"},{"authors":["Malar"],"categories":null,"content":"Dr. Malarvizhi Kaniappan Chinnathai is a Lecturer in Modelling of Discrete Event Processes at the University of Exeter. She is a member of the Exeter Digital Enterprise Systems (ExDES) research group. Prior to joining Exeter, she served as a Lecturer in the School of Computer Science and Engineering at the University of Westminster (2022–2025). She previously held the position of Research Fellow at the Brunel Innovation Centre, Brunel University London, following her role as Project Engineer (Digital Manufacturing) in the Automation Systems Group at the Warwick Manufacturing Group (WMG), University of Warwick. Dr. Chinnathai earned her PhD in Engineering (2021) and MSc in Manufacturing Systems Engineering (2015) from the University of Warwick.\nHer research focuses on the development and application of discrete event simulation for decision support in manufacturing scale-up, operations research, electric vehicle (EV) assembly, process planning, and intelligent logistics for manufacturing systems. She has also conducted extensive research in machine learning and computer vision for non-destructive testing (NDT) to enable zero-defect manufacturing.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1769428425,"objectID":"d8a08bdfdc50a4b91ccbe6053f1ba80f","permalink":"https://hci2.uk/author/malarvizhi-kaniappan-chinnathai/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/malarvizhi-kaniappan-chinnathai/","section":"authors","summary":"Dr. Malarvizhi Kaniappan Chinnathai is a Lecturer in Modelling of Discrete Event Processes at the University of Exeter. She is a member of the Exeter Digital Enterprise Systems (ExDES) research group. Prior to joining Exeter, she served as a Lecturer in the School of Computer Science and Engineering at the University of Westminster (2022–2025). She previously held the position of Research Fellow at the Brunel Innovation Centre, Brunel University London, following her role as Project Engineer (Digital Manufacturing) in the Automation Systems Group at the Warwick Manufacturing Group (WMG), University of Warwick. Dr. Chinnathai earned her PhD in Engineering (2021) and MSc in Manufacturing Systems Engineering (2015) from the University of Warwick.\nHer research focuses on the development and application of discrete event simulation for decision support in manufacturing scale-up, operations research, electric vehicle (EV) assembly, process planning, and intelligent logistics for manufacturing systems. She has also conducted extensive research in machine learning and computer vision for non-destructive testing (NDT) to enable zero-defect manufacturing.\n","tags":null,"title":"Malarvizhi Kaniappan Chinnathai","type":"authors"},{"authors":["Min"],"categories":null,"content":"Myo Nyi Nyi Min is a PhD researcher in Artificial Intelligence with a focus on human–AI collaboration and intelligent automation. His research explores how trust and decision-making can be optimized between humans and AI systems, integrating machine learning, robotics, and digital twin technologies. He holds an MSc in Artificial Intelligence from the University of Surrey, where his dissertation developed a hybrid Conv-TasNet and Conformer model for real-time speech enhancement. Alongside academic research, he has professional experience in software development and DevOps, specializing in FastAPI, Kubernetes, and cloud-based AI services. He is passionate about creating applied AI systems that improve human productivity and support ethical, transparent decision-making. His long-term goal is to advance research that bridges technical innovation with human-centred design in intelligent systems.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1769428425,"objectID":"312ae1f5b3609e46708af7a8151d86c5","permalink":"https://hci2.uk/author/myo-nyi-nyi-min/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/myo-nyi-nyi-min/","section":"authors","summary":"Myo Nyi Nyi Min is a PhD researcher in Artificial Intelligence with a focus on human–AI collaboration and intelligent automation. His research explores how trust and decision-making can be optimized between humans and AI systems, integrating machine learning, robotics, and digital twin technologies. He holds an MSc in Artificial Intelligence from the University of Surrey, where his dissertation developed a hybrid Conv-TasNet and Conformer model for real-time speech enhancement. Alongside academic research, he has professional experience in software development and DevOps, specializing in FastAPI, Kubernetes, and cloud-based AI services. He is passionate about creating applied AI systems that improve human productivity and support ethical, transparent decision-making. His long-term goal is to advance research that bridges technical innovation with human-centred design in intelligent systems.\n","tags":null,"title":"Myo Nyi Nyi Min","type":"authors"},{"authors":["Naimul"],"categories":null,"content":"Naimul Hasan is a PhD student at London South Bank University, UK. His research focuses on intelligent manufacturing systems, distributed robotics, and automation, with particular interest in Industry 5.0 and human-machine interaction. He has worked on projects involving computer vision and deep learning for industrial applications, including assembly error tracking and metal casting defect detection. Naimul has been actively contributing to advancing automation through AI-driven solutions.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1769428425,"objectID":"3c7dafe4b636fc33428a268fe93d5bd3","permalink":"https://hci2.uk/author/naimul-hasan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/naimul-hasan/","section":"authors","summary":"Naimul Hasan is a PhD student at London South Bank University, UK. His research focuses on intelligent manufacturing systems, distributed robotics, and automation, with particular interest in Industry 5.0 and human-machine interaction. He has worked on projects involving computer vision and deep learning for industrial applications, including assembly error tracking and metal casting defect detection. Naimul has been actively contributing to advancing automation through AI-driven solutions.\n","tags":null,"title":"Naimul Hasan","type":"authors"},{"authors":null,"categories":null,"content":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1759149040,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://hci2.uk/author/nelson-bighetti/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/nelson-bighetti/","section":"authors","summary":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\n","tags":null,"title":"Nelson Bighetti","type":"authors"},{"authors":["Zarin"],"categories":null,"content":"Zarin Shabab is a Research Intern at London South Bank University, working within the Human-Centred Industrial Intelligence Lab in the School of Computer Science and Digital Technologies. Her research focuses on AI-driven ergonomic risk assessment, combining MediaPipe-based pose estimation, upper-limb joint-angle modelling, and automated RULA scoring to enable real-time, low-cost monitoring of human posture. She has developed and validated an intelligent ergonomic assessment framework in a real-world workstation scenario, contributing to advanced research in computer vision, human–machine interaction, and human-centred safety systems aligned with Industry 4.0/5.0.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1764665662,"objectID":"7fb67d63a5326ad58227c7ce4ab12816","permalink":"https://hci2.uk/author/zarin-shabab/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/zarin-shabab/","section":"authors","summary":"Zarin Shabab is a Research Intern at London South Bank University, working within the Human-Centred Industrial Intelligence Lab in the School of Computer Science and Digital Technologies. Her research focuses on AI-driven ergonomic risk assessment, combining MediaPipe-based pose estimation, upper-limb joint-angle modelling, and automated RULA scoring to enable real-time, low-cost monitoring of human posture. She has developed and validated an intelligent ergonomic assessment framework in a real-world workstation scenario, contributing to advanced research in computer vision, human–machine interaction, and human-centred safety systems aligned with Industry 4.0/5.0.\n","tags":null,"title":"Zarin Shabab","type":"authors"},{"authors":null,"categories":null,"content":"This project develops a multi-fidelity, policy-oriented Digital Twin (DT) for resilient Autonomous Mobile Robot (AMR) fleet management under disruption. The system monitors shop-floor telemetry via OPC-UA, classifies incidents (e.g., AMR breakdown, machine unavailability, demand shock), snapshots decision-relevant state, then generates incident-aware recovery schedules under a strict decision-time cap. A surrogate (low-fidelity) optimisation layer produces deployable responses within seconds, while a high-fidelity DT simulation layer provides audit, assurance, and post-decision validation. An operator-in-the-loop panel exposes Pareto trade-offs and schedule previews, enabling transparent selection, re-simulation on demand, and policy-bound overrides, with provenance captured as machine-readable decision artefacts.\nMotivation As AMR fleets scale, small disruptions propagate into congestion, energy waste, and missed throughput targets. Rule-based fleet managers are fast but brittle and opaque during incidents, while high-fidelity simulation is informative but too slow for time-critical response. This project addresses the gap with a governed multi-fidelity DT, fast enough for real-time recovery, and structured enough for auditability, human oversight, and Industry 5.0–ready deployment. System Architecture Physical \u0026amp; Communication Layer AMRs, stations, sensors, and execution systems stream telemetry and events via OPC-UA Event-driven incident triggers (e.g., fault flags, demand-change flags) initiate response Data \u0026amp; Digital Shadow Layer Telemetry is contextualised and stored (time-series + event envelopes) On incident, the system snapshots decision-relevant state, remaining jobs, resource availability, and constraints Digital Layer, Multi-Fidelity Decision Support Surrogate optimisation (low-fidelity) Generates recovery schedules under a strict decision-time budget Targets throughput (makespan) and energy-related objectives High-fidelity DT simulation Executes candidate schedules to validate behavioural realism (e.g., interactions, congestion effects) Used for audit, assurance, and scenario analysis Human–Machine Interaction Layer (Operator Panel) Live incident status and fleet state Pareto front exploration (trade-off selection) Gantt schedule previews and validation Re-simulation requests and policy-bound overrides with rationale Governance \u0026amp; Provenance Layer Every incident and decision step is logged with timestamps, reason codes, response type, and operator actions Artefacts support traceability, cross-shift handover, and post hoc analysis Key Components Incident Response Module (IRM)\nDetects incidents from OPC-UA alerts, classifies event type, snapshots state, and triggers recovery.\nResponse Selector \u0026amp; Model Allocation\nChooses surrogate-only response vs surrogate + audit vs high-fidelity escalation depending on incident severity, policy, and confidence.\nSurrogate-Based Optimisation\nMulti-objective rescheduling under time constraints, balancing throughput and energy-related KPIs while enforcing feasibility and safety constraints.\nHigh-Fidelity DT Audit\nValidates surrogate decisions, quantifies surrogate–simulation agreement, and provides assurance evidence under disruption.\nOperator Panel (Human-in-the-Loop)\nSupports trade-off selection (Pareto), schedule inspection (Gantt), re-simulation, and controlled overrides.\nDecision Artefacts \u0026amp; Incident Log\nStructured outputs (status JSON, Pareto results, schedule images, metrics, incident log) enabling governance and reproducibility.\nEvaluation The framework is instantiated in an intralogistics use case representing a battery module assembly flowshop, where AMRs transport materials between stations. Evaluation introduces controlled disruption classes to stress-test response performance:\nAMR Breakdown (AMRBD)\nTransport capacity loss, task reassignment, utilisation shift.\nMachine Breakdown (MBD)\nReduced station availability, increased queueing pressure, precedence constraints.\nDemand Change (DC)\nHigh-priority job injection, schedule reordering, system-wide stress.\nMetrics and evidence focus on:\nDecision latency (stage-resolved, including detection, optimisation, audit/re-simulation, dispatch) Makespan and energy deviation relative to nominal and baseline dispatch rules Schedule stability (reassignments and disturbance propagation) Surrogate–simulation agreement (validity under high-fidelity execution) Governance behaviour (policy modes, fidelity escalation, operator intervention pathways) Key Findings Seconds-level incident recovery\nSurrogate optimisation delivers time-bounded rescheduling appropriate for operational incident response.\nMulti-fidelity assurance\nHigh-fidelity DT execution provides an auditable validation layer, enabling confidence-aware escalation rather than blanket simulation.\nHuman-in-the-loop governance\nOperator panel interactions (trade-off selection, validation requests, overrides) support accountable decision-making without sacrificing …","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1771326578,"objectID":"c9e3d79e3eb83f396773ecb18f034654","permalink":"https://hci2.uk/research/digitaltwin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/research/digitaltwin/","section":"research","summary":"Building a policy-oriented, human-in-the-loop Digital Twin for incident-aware AMR fleet management, combining OPC-UA event monitoring, time-bounded surrogate optimisation, and high-fidelity simulation for governed, resilient intralogistics.\n","tags":["AMR","Intralogistics","Incident-aware","Surrogate Opt","Simulation Audit","Governance"],"title":"Human-in-the-Loop Digital Twin for Resilient AMR Fleet Management","type":"research"},{"authors":null,"categories":null,"content":"This project develops a safety-aware anomaly detection and RUL analytics pipeline for industrial machinery, grounded in demonstrator evidence rather than purely offline datasets. Using the bottle inspection and sorting system, we capture multi-sensor telemetry (signals from actuators, conveyors, inspection modules, and control logic), align it into machine-state segments, then learn normal operational signatures to detect deviation patterns early. Beyond detection, the framework estimates degradation trends and Remaining Useful Life with uncertainty bounds, enabling maintenance planning that is both operationally useful and defensible.\nA core requirement is auditability, every alert is paired with traceable evidence (when the deviation started, which signals contributed, confidence/uncertainty, and operator validation outcome), enabling post hoc analysis, governance, and cross-shift handover.\nMotivation Industrial anomaly detection is often evaluated on static datasets, but deployment fails when alarms are noisy, poorly explained, or misaligned with safety and operational decision-making. In inspection and sorting cells, late fault detection can create cascading issues, mis-sorts, quality escapes, downtime spikes, and unsafe recovery actions. This project focuses on early and explainable detection, RUL-style forecasting, and human verification, so the outputs are usable in real maintenance and operations workflows. System Architecture Sensing \u0026amp; Control Layer Demonstrator telemetry from PLC/control events plus sensor streams (time-series + event logs) Production context signals, e.g., mode, recipe, throughput rate, inspection outcomes Data Layer Synchronisation, cleaning, and machine-cycle segmentation Feature store for time-domain, frequency-domain, and event-derived features Ground-truth support via fault logs, interventions, and controlled fault injection (where feasible) Learning Layer (Detection + Prognostics) Anomaly Detection Learns normal operational signatures per mode/recipe Detects deviations using confidence-aware thresholds and persistence logic RUL / Degradation Modelling Health indicator construction and trend modelling RUL prediction with uncertainty bounds (intervals), not just point estimates Human-in-the-Loop Layer Alarm triage panel, operator labels, “confirmed / not an issue / needs monitoring” Feedback improves calibration, reduces false positives, and builds trust Governance \u0026amp; Audit Layer Alarm evidence packs, timestamps, signal attribution, and decision rationale Machine-readable artefacts enabling traceability and reproducibility Key Components Cycle \u0026amp; State Segmenter\nPartitions telemetry into meaningful machine phases (conveyor motion, inspection window, sorting actuation), ensuring anomalies are contextual rather than global.\nMode-Aware Normality Model\nSeparates “expected variation” (different bottle types, throughput levels, lighting changes) from true abnormality.\nAnomaly Scoring + Alarm Logic\nCombines raw anomaly scores with persistence, cooldown, and confidence gates to avoid alert storms.\nRUL / Degradation Module\nBuilds interpretable health indicators, estimates trends, and outputs RUL with uncertainty intervals.\nExplainability \u0026amp; Evidence Pack Builder\nProduces “what changed” summaries, signal contributions, and local time windows around onset.\nOperator Panel + Feedback Loop\nLets users validate alarms, attach notes, and trigger targeted re-analysis.\nEvaluation The framework is evaluated on the NED bottle inspection and sorting demonstrator under controlled and naturally occurring variability.\nDisruption / anomaly classes include:\nConveyor/drive anomalies\nSpeed drift, intermittent stalls, rising vibration signatures, abnormal cycle-time variance. Inspection degradation\nSensor noise increase, lighting drift, mis-detection patterns, inspection latency spikes. Sorting/actuation issues\nDelay or misfire behaviours, increasing rejection errors, timing misalignment with conveyor state. Process/context shifts\nRecipe changes, throughput changes, environmental shifts, which must not be misclassified as faults. Metrics and evidence focus on:\nDetection lead time before failure or intervention False alarm rate, missed detection rate, and alert stability RUL calibration (interval coverage, not only point error) Robustness across operating modes/recipes Operator agreement and triage effectiveness Audit completeness (can we reconstruct why an alert fired) Key Findings Earlier fault visibility\nMode-aware baselines reduce nuisance alarms while preserving sensitivity to true degradation. Operationally usable RUL\nUncertainty-bounded outputs support planning decisions rather than overconfident predictions. Trust via auditability\nEvidence packs and operator validation pathways make alarms defensible and easier to adopt. Demonstrator-first realism\nDemonstrator evaluation exposes deployment issues (context shifts, phase alignment, alert storms) that static datasets often hide. ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1771326562,"objectID":"a66705ebd9340a901d9738f1c967d7e5","permalink":"https://hci2.uk/research/anomaly/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/research/anomaly/","section":"research","summary":"Developing an auditable, safety-aware anomaly detection and Remaining Useful Life (RUL) analytics pipeline for industrial machinery, validated on our bottle inspection and sorting demonstrator, combining multi-sensor time-series learning, uncertainty-aware alarms, and human-in-the-loop verification.\n","tags":["Anomaly Detection","Predictive Maintenance","RUL","Industrial AI","Auditability","Human-in-the-Loop"],"title":"Safety-Aware Anomaly Detection and RUL Analytics for Industrial Machinery","type":"research"},{"authors":null,"categories":null,"content":"","date":1763856e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1765461476,"objectID":"637f68f790b5540479f53a0f599678e4","permalink":"https://hci2.uk/teaching/ai/","publishdate":"2025-11-23T00:00:00Z","relpermalink":"/teaching/ai/","section":"teaching","summary":"","tags":null,"title":"Artificial Intelligence","type":"landing"},{"authors":null,"categories":null,"content":"","date":1763856e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1765418522,"objectID":"94ab1adde5b6e0123f6cc3a9d9d1d2bb","permalink":"https://hci2.uk/teaching/icps/","publishdate":"2025-11-23T00:00:00Z","relpermalink":"/teaching/icps/","section":"teaching","summary":"","tags":null,"title":"Industrial Cyber-Physical Systems","type":"landing"},{"authors":[],"categories":null,"content":"","date":1762952400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1771332501,"objectID":"1844999606b5d0d498965af763dada17","permalink":"https://hci2.uk/event/swarmexc/","publishdate":"2025-11-12T13:00:00Z","relpermalink":"/event/swarmexc/","section":"event","summary":"Hands-on training on swarm robots.","tags":[],"title":"HCI² Lab Presents- The 2025 Kilobot Swarm Intelligence Extra-Curricular Activity","type":"event"},{"authors":["Bugra Alkan","Louie Webb","Mohammad Osman Tokhi"],"categories":null,"content":" ","date":1760486400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1769428425,"objectID":"36abce6a49cff47eca929dbe95162304","permalink":"https://hci2.uk/publication/preprint/preprint2/","publishdate":"2025-10-15T00:00:00Z","relpermalink":"/publication/preprint/preprint2/","section":"publication","summary":"","tags":null,"title":"A Novel Adaptive AMR Fleet Management System Leveraging AI-enabled Digital Twin for Agile Incident Response and Improved Shop-floor Efficiency","type":"publication"},{"authors":["Naimul Hasan","Bugra Alkan"],"categories":null,"content":" ","date":1753574400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1769428425,"objectID":"510b1f382a20cb33b2fa6021b0bd0e58","permalink":"https://hci2.uk/publication/journal-article/journal1/","publishdate":"2025-07-27T00:00:00Z","relpermalink":"/publication/journal-article/journal1/","section":"publication","summary":"","tags":null,"title":"Gest-SAR: A Gesture-Controlled Spatial AR System for Interactive Manual Assembly Guidance with Real-Time Operational Feedback","type":"publication"},{"authors":["Hasan Cezayirli","Halil Tetik","Mehmet İsmet Can Dede","Wai Lwin Phone","Bugra Alkan"],"categories":null,"content":" ","date":1749686400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1769428425,"objectID":"38a636a4cd9e728e38d6793fba39e480","permalink":"https://hci2.uk/publication/conference-paper/conference2/","publishdate":"2025-06-12T00:00:00Z","relpermalink":"/publication/conference-paper/conference2/","section":"publication","summary":"","tags":null,"title":"A Comparative Study of Attention-Augmented YOLO Architectures for Defect Detection in Fused Deposition Modelling","type":"publication"},{"authors":["Shepherd, Paul","Tasos Dagiuklas","Bugra Alkan","Jonathan Rodriguez"],"categories":null,"content":" ","date":1749686400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1769428425,"objectID":"19b83e29fbd887143b647ee3a12ea169","permalink":"https://hci2.uk/publication/conference-paper/conference1/","publishdate":"2025-06-12T00:00:00Z","relpermalink":"/publication/conference-paper/conference1/","section":"publication","summary":"","tags":null,"title":"Dynamic Trust Management for Secure Federated Learning in Critical Industrial and IoT Networks","type":"publication"},{"authors":["Bugra Alkan","Naimul Hasan","Louie Webb","Malarvizhi Kaniappan Chinnathai"],"categories":null,"content":" ","date":1735689600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1769428425,"objectID":"f244e22f312ae3b9cf88f52e6de38d5e","permalink":"https://hci2.uk/publication/preprint/preprint1/","publishdate":"2025-01-01T00:00:00Z","relpermalink":"/publication/preprint/preprint1/","section":"publication","summary":"","tags":null,"title":"Spatial Augmented Reality in Manual Assembly: An Empirical Investigation of Its Effects on Assembly Performance and Cognitive Ergonomics","type":"publication"},{"authors":["Louie Webb","Osman M. Tokhi","Bugra Alkan"],"categories":null,"content":" ","date":1724198400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1769428425,"objectID":"f81f52fbb472ee3dd498693ead3e4288","permalink":"https://hci2.uk/publication/journal-article/journal2/","publishdate":"2024-08-21T00:00:00Z","relpermalink":"/publication/journal-article/journal2/","section":"publication","summary":"","tags":null,"title":"State of the art and future directions of digital twin-enabled smart assembly automation in discrete manufacturing industries","type":"publication"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1770370625,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://hci2.uk/people/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"People","type":"landing"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1771342163,"objectID":"968aeb08e377e3887169e217782719e3","permalink":"https://hci2.uk/research/hrc/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/research/hrc/","section":"research","summary":"","tags":null,"title":"","type":"research"},{"authors":["Naimul Hasan","Louie Webb","Malarvizhi Kaniappan Chinnathai","Bugra Alkan"],"categories":null,"content":"This project develops a human-centric Spatial Augmented Reality (SAR) system that projects adaptive, light-guided (dis)assembly instructions directly onto the workspace and is controlled through AI-based hand gesture recognition. The system delivers real-time guidance and error feedback without requiring handheld or wearable devices. Beyond guidance, the framework is designed as an intelligent operator assistance system that augments physical and cognitive capabilities, informing users about posture-related physical risk and cognitive state (e.g., workload) while protecting operator identity via privacy-by-design sensing and data handling. User studies show significant reductions in task time, error rates, and perceived workload compared to conventional instruction methods.\nMotivation This project addresses limitations of conventional assembly instructions that rely on static manuals or wearable devices. By projecting guidance directly onto the workspace, SAR reduces cognitive load and improves task flow. The project further targets Industry 5.0 operator assistance by extending SAR from guidance-only to capability augmentation, combining task awareness with posture and cognitive-state feedback under privacy-preserving constraints suitable for real shop-floor deployment. System Architecture The system integrates computer vision, gesture recognition, and spatial projection to deliver adaptive (dis)assembly instructions in real time. A closed-loop operator assistance layer estimates task progress and deviations, then adapts projected cues and feedback. Optional operator-state modules provide posture-aware physical support and cognitive workload cues, enabling adaptive assistance without exposing operator identity. Key Components Vision-based workspace perception (parts/steps/progress verification) Gesture-controlled SAR interface for touchless step navigation and confirmations Projection mapping and calibration for spatially registered overlays Error detection and feedback cues (missed step, wrong part/order, misalignment) Operator assistance modules (posture/physical risk cues, cognitive workload inference) Privacy-by-design pipeline (identity suppression, minimal logging, policy-based retention) Evaluation User studies compared SAR guidance with conventional instructions. Participants showed reduced completion time and fewer errors. Evaluation also considers cognitive ergonomics and operator acceptance, and, where enabled, assesses the feasibility of posture- and workload-aware assistance under privacy-preserving sensing constraints. Key Findings Faster task completion Lower error rate Reduced perceived workload Improved interaction flow via touchless gesture control Practical pathway to privacy-preserving operator assistance (capability augmentation) ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1771328556,"objectID":"d4547322978d466cbe294c883a19775e","permalink":"https://hci2.uk/research/sar/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/research/sar/","section":"research","summary":"Developing a computer vision-enabled Spatial Augmented Reality framework for intelligent, privacy-preserving operator assistance in human-centric smart (dis)assembly.\n","tags":["Spatial AR","Computer Vision","Gesture Interaction","Human-in-the-Loop","Operator State","Privacy-by-Design"],"title":"Human-Centric Spatial Augmented Reality for Interactive (Dis)assembly Operator Assistance","type":"research"}]